\documentclass[8pt]{extarticle}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage[a4paper,left=2.3cm,right=1.2cm,top=2cm,bottom=2cm]{geometry} 
\usepackage{blindtext}
\usepackage{setspace}
\usepackage{float}
\usepackage{titletoc}
\usepackage{titlesec}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{amsmath} 
\usepackage{multicol}
\usepackage{amsfonts} 
\usepackage{comment}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage{wrapfig}
\usepackage{verbatimbox}
\usepackage{enumitem}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{bigints}
\onehalfspacing
\usepackage[hidelinks]{hyperref}
\usepackage[all]{nowidow} %funktioniert nicht....
\clubpenalty=9996
\widowpenalty=9999
\brokenpenalty=4991
\predisplaypenalty=10000
\postdisplaypenalty=1549
\displaywidowpenalty=1602
\usepackage[round]{natbib} 
\usepackage{enumitem}

\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}

\allowdisplaybreaks

\setlength\parindent{0pt}

\newcommand{\zerodisplayskips}{%
  \setlength{\abovedisplayskip}{2pt}%
  \setlength{\belowdisplayskip}{2pt}%
  \setlength{\abovedisplayshortskip}{2pt}%
  \setlength{\belowdisplayshortskip}{2pt}}
\appto{\normalsize}{\zerodisplayskips}
\appto{\small}{\zerodisplayskips}
\appto{\footnotesize}{\zerodisplayskips}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\indep}{\perp \!\!\! \perp}

%Hier sind die unterschiedlichen Ausführlichkeitsgrade definiert
\includecomment{Extensiv} 
\includecomment{Proof} 
\includecomment{Annahmen}
\includecomment{Mathspez}
\includecomment{Mathfolg}
\includecomment{Rechreg}
\mdfdefinestyle{MyFrame}{%
    linecolor=black!20!,
    outerlinewidth=0.2pt,
    roundcorner=5pt,
    innertopmargin=0.5\baselineskip,
    innerbottommargin=0.5\baselineskip,
    innerrightmargin=10pt,
    innerleftmargin=10pt,
    backgroundcolor=white}
\specialcomment{Proof}{\begin{mdframed}[style=MyFrame,nobreak=true] Proof: \ \\}{\end{mdframed}}
\specialcomment{Rechreg}{\noindent \textit{Calculation Rules:} \begin{itemize}[nosep,label=$\star$] }{\end{itemize}}
\renewcommand\ThisComment[1]{% Fix for Umlauts in comments
  \immediate\write\CommentStream{\unexpanded{#1}}%
}

% Hier die Ausführlichkeit bestimmen:
%\excludecomment{Extensiv} 
%\excludecomment{Proof} 
%\excludecomment{Annahmen}
%\excludecomment{Mathspez}
%\excludecomment{Mathfolg}

% Inhaltsverzeichnis mit zwei Spalten
\usepackage[toc]{multitoc}
\renewcommand*{\multicolumntoc}{2}




%Überschriftengrößen anpassen, so dass Paragraph kleiner ist als Subsubsection
\titleformat{\section}
  {\normalfont\fontsize{16}{15}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\fontsize{14}{15}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalfont\fontsize{12}{15}\bfseries}{\thesubsubsection}{1em}{}


\begin{document}

\topskip0pt
\vspace*{18em}

\hrule
\begin{center}
{\fontsize{30}{60}\selectfont \textbf{Causal Inference}} \\ \

{\fontsize{20}{60}\selectfont a summary}
\end{center}
\hrule

\tableofcontents




% weitere Anpassungen im Hauptteil des Dokuments
\raggedright %linksbündig
\setlength{\parindent}{15pt} %Einzuglänge festsetzen
\setlength{\columnseprule}{0.3pt} %Liniendicke zwischen zwei Multicols






%-------------------------------------------------------------------------------

% SECTION: GENERAL

%-------------------------------------------------------------------------------

\section{General}

\begin{multicols}{2}

\paragraph{\large Causal Roadmap} \citep{petersen2014causal} 
systematic approach linking causality to statistical procedures

\noindent \textbf{1. Specifying Knowledge.} structural causal model (unifying counterfactual language, structural equations, \& causal graphs): a set of possible data-generating processes, expresses background knowledge and its limits

\noindent \textbf{2. Linking Data.} specifying measured variables and sampling specifics (latter can be incorporated into the model)

\noindent \textbf{3. Specifying Target.} define hypothetical experiment: decide
\noindent\begin{enumerate}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item variables to intervene on: one (point treatment), multiple (longitudinal, censoring/missing, (in)direct effects)
\item intervention scheme: static, dynamic, stochastic
\item counterfactual summary of interest: absolute or relative, marginal structural models, interaction, effect modification
\item population of interest: whole, subset, different population
\end{enumerate}

\noindent \textbf{4. Assessing Identifiability.} are knowledge and data sufficient to derive estimand and if not, what else is needed?

\noindent \textbf{5. Select Estimand.} current best answer: knowledge-based assumptions $+$ which minimal convenience-based asspumptions (transparency) gets as close as possible

\noindent \textbf{6. Estimate.} choose estimator by statistical properties, nothing causal here

\noindent \textbf{7. Interpret.} hierarchy: statistical, counterfactual, feasible intervention, randomized trial



\paragraph{Notation} chapter 1.1

\paragraph{average causal effect} chapter 1.2 and 1.3 and 1.4 and 1.5

\paragraph{randomized experiments (target trial)} 2.1 and 2.2; 3.6

\paragraph{\large Standardization} plug-in (or parametric if so) g-formula
$$\mathrm{E}\left[Y|A=a\right] = \int \mathrm{E}\left[Y|L=l, A=a\right]dF_L\left[l\right]$$
weighted average of stratum-specific risks; unknowns can be estimated non-parametrically or modeled

\noindent \textbf{no need to estimate $\boldsymbol{f_L\left[l\right]}$} as empirical distribution can be used: estimate outcome model $\rightarrow$ predict counterfactuals $\rightarrow$ average the results ($\rightarrow$ CI by bootstrapping)

\noindent \textbf{for discrete $\boldsymbol{ L}$}  $\mathrm{E}\left[Y|A=a\right] = \sum_l \mathrm{E}\left[Y|L=l, A=a\right]\mathrm{Pr}\left[L=l\right]$

\paragraph{\large IP Weighting} adjust for (surrogate) confounders $L$
$$\mathrm{E}\left[Y|A=a\right] = \mathrm{E}\left[\frac{I(A=a)Y}{f\left[A|L\right]}\right]; W^A=\frac{1}{f\left[A|L\right]}; SW^A = \frac{f(A)}{f\left[A|L\right]}$$

\noindent unknowns can be estimated non-parametrically or modeled
\noindent \textbf{pseudo-population:} everyone is treated \& untreated ($L\not\to A$)

\noindent \textbf{FRCISTG} \textit{(fully randomized causally interpreted structured graph)}: probability tree for $L \rightarrow A \rightarrow Y$, can be used to calculate/visualize simulation of values for $A$ 

\noindent \textbf{for discrete $\boldsymbol{A, L}$} $f\left[a|l\right] = \mathrm{Pr}\left[A=a,L=l\right]$

\noindent \textbf{estimators:} Horvitz-Thompson; Hajek (modified version) %todo p.152 

\noindent \textbf{stabilized weights $\boldsymbol{SW^A}$} should have an average of 1 (check!) $\rightarrow$ pseudo-population same size $\rightarrow$ CI width $\downarrow$

\paragraph{\large Standardization and IP Weighting}

are equivalent, \textit{\textbf{but}} if modeled, different ``no misspecification'' assumptions:

standardization: outcome model

IP weighting: treatment model

\noindent \textbf{doubly robust estimators:} reduce model misspecification bias, consistent if either model is correct; \textbf{\textit{e.\,g.:}} \vspace{-0.9em}

1. fit outcome regression with variable $R = \begin{cases} +W^A & \text{if } A{=}1 \\ -W^A & \text{if } A{=}0 \end{cases}$ \vspace{-0.9em}

2. standardize by averaging




\paragraph{identifiability conditions} most of 3

positivity: p. 155, p. 162

additional conditions: chapter 13.5

exchangeability: p 172f


positivity: $f_L(l)\neq 0 \Rightarrow f_{A|L}(a|l)>0 \,\, \forall a,l$


consistency:  if $A=a$, then $Y^a=Y$ for each individual




\paragraph{effect modification} chapter 4

\paragraph{interaction} chapter 5

\paragraph{causal diagrams} chapter 6, include swigs from 7.5 and that one technical point

more on SWIGS p 242ff

\paragraph{confounding} chapter 7

\paragraph{selection bias} chapter 8

\paragraph{measurement bias} chapter 9

\paragraph{random variabilty} chapter 10



\end{multicols}



%-------------------------------------------------------------------------------

% SECTION: MODELS

%-------------------------------------------------------------------------------

\section{Models}
\begin{multicols}{2}

\paragraph{\large Modeling} data are a sample from the target population \vspace{0.4em}

\noindent \hspace{0.9em}\begin{tabular}{l l l}
\textbf{\it estimand:} & quantity  of interest, & e.\,g. $\mathrm{E}\left[Y|A=a\right]$ \\
\textbf{\it estimator:} & function to use, & e.\,g. $\widehat{\mathrm{E}}\left[Y|A=a\right]$ \\
\textbf{\it estimate:} & apply function to data, & e.\,g. $4.1$ 
\end{tabular} \vspace{0.5em}

\noindent \textbf{model}: a priori restriction of joint distribution/dose-response curve;  \textit{assumption:} no model misspecification (usually wrong)

\noindent \textbf{non-parametric estimator:} no restriction (saturated model) $=$ \textit{Fisher consistent estimator} (entire population data $\rightarrow$ true value)

\noindent \textbf{parsimonious model:} few parameters estimate many quantities

\noindent \textbf{bias-variance trade-off:} \newline wiggliness $\uparrow$ $\rightarrow$ misspecification bias $\downarrow$, CI width $\uparrow$


\paragraph{\large Marginal Structural Models} association is causation in the IP weighted pseudo-population 
$$\text{associational model } \mathrm{E}\left[Y|A\right] = \text{ causal model } \mathrm{E}\left[Y^a\right]$$

\noindent \textit{step 1:} estimate/model $f\left[A|L\right]$ (and $f\left[A\right]$) $\rightarrow$ get $(S)W^A$

\noindent \textit{step 2:} estimate regression parameters for pseudo-population

\noindent \textbf{effect modification} variables $V$ can be included (e.\,g. $\beta_0+\beta_1 a+\beta_2 V a + \beta_3 V$; technically not marginal anymore), $SW^A(V) = \frac{f\left[A|V\right]}{f\left[A|L\right]}$ more efficient than $SW^A$
 

\paragraph{\large Censoring} measuring joint effect of $A$ and $C$
$$\mathrm{E}\left[Y^{a, c=0}\right] \text{ is of interest}$$

\noindent \textbf{standardization} $\mathrm{E}\left[Y|A=a\right] = \int \mathrm{E}\left[Y|L{=}l, A{=}a, C{=}0\right]dF_L\left[l\right]$\vspace{0.2em}

\noindent \textbf{IP weights}\vspace{-1.30em}

\hspace{3.5em}\begin{tabular}{l l l}
$W^{A,C}=W^A \times W^C$  &(uses $n$) & or \\
$SW^{A,C}=SW^A \times SW^C$ &(uses $n^{c=0}$) & 
\end{tabular}\vspace{0.3em}

\noindent \textbf{g-estimation} can only adjust for confounding, not selection bias $\rightarrow$ use IP weights



\paragraph{\large G-Methods} \textit{g}eneralized treatment contrasts:
adjust for (surrogate) confounders $L$
\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item \textbf{standardization}
\item \textbf{IP weighting}
\item \textbf{g-estimation:} not needed unless longitudinal
\end{itemize}


\paragraph{\large G-Estimation} (additive) structural nested models %todo: verbesserung von allem, ich habs noch nicht ganz verstanden
\begin{align*}
\mathrm{logit} \, \mathrm{Pr}\left[A=1|H(\psi^\dagger), L\right] &= \alpha_0 + \alpha_1H(\psi^\dagger) + \alpha_2L \\
H(\psi^\dagger) &= Y - \psi_\dagger A
\end{align*}
find $\psi^\dagger$ which renders $\alpha_1=0$; 95\,\%-CI: all $\psi^\dagger$ for which $p>0.05$
closed-form solution for linear models


\noindent \textbf{derivation:} $H(\psi^\dagger) = Y^{a=0}$
$$\mathrm{logit} \, \mathrm{Pr}\left[A=1|Y^{a=0}, L\right] = \alpha_0 + \alpha_1Y^{a=0} + \alpha_2L$$
$Y^{a=0}$ unknown, but because of exchangeability $\alpha_1$ should be zero
$$Y^{a=0} =Y^a - \psi_1 a$$
equivalent to $Y^{a=0} =Y^{a=1} - \psi_1$, but using no counterfactuals



\noindent \textbf{structural nested mean model}
\begin{align*}
\text{additive: }\,\,\, & \mathrm{E}\left[Y^a-Y^{a=0}|A=a, L\right] &= \beta_1 a \,(+ \beta_2 a L) \\
\text{multiplicative: }\,\,\, & \log \left( \frac{\mathrm{E}\left[Y^a|A=a, L\right]}{\mathrm{E}\left[Y^{a=0}|A=a, L\right]} \right) &= \beta_1 a \,(+ \beta_2 a L)
\end{align*} 
multiplicative is preferred if $Y$ always positive, but does not extend to longitudinal case

\noindent semi-parametric: agnostic about $\beta_0$ and effect of $L$ $\rightarrow$ robust $\uparrow$

\noindent \textbf{no time-varying:} no nesting; model equals marginal structural models with missing $\beta_0, \beta_3$ (unspecified ``no treatment'')

\noindent \textbf{sensitivity analysis:} unmeasured confounding ($\alpha_1 \neq 0$) can be examined: do procedure  for different values of $\alpha_1$ $\rightarrow$ plot $\alpha_1$ vs.\ $\psi^\dagger$ $\rightarrow$ how sensitive is  estimate to unmeasured confounding?

\noindent \textbf{effect modification:} add $V$ in both g-estimation equations %todo


\noindent \textbf{doubly robust estimators} exist%todo













\paragraph{Outcome regression} chapter 15

\paragraph{instrumental variable estimation} chapter 16

\paragraph{causal survival analysis} chapter 17

\paragraph{\large Variable Selection} can induce bias if $L$ includes: 

\hspace{-0.2em}\vspace{-1em}
\begin{tabular}{l l }
 (decendant of) collider:& \textit{selection bias under the null}\\
 noncollider effect of $A$:& \textit{selection bias under the alternative}\\
 mediator:& \textit{overadjustment for mediators}
\end{tabular}

\noindent temporal ordering is not enough to conclude anything

\noindent \textbf{bias amplification:} e.g. by adjusting for an instrument $Z$ (can also reduce bias)





\paragraph{\large Machine Learning} $L$ is high-dimensional

\noindent use lasso or ML for IP weighting/standardization

\noindent \textbf{\textit{but:}} ML does not guarantee elimination of confounding and has largely unknown statistical properties

\noindent $\rightarrow$ \textbf{doubly robust estimator:} consistent if bias  $< \frac{1}{\sqrt{n}}$

\noindent \textit{sample splitting:} train estimators on training sample, use resulting estimators for doubly robust method on estimation sample (CIs on estimation sample are valid, but $n$ halved)

\noindent \textit{cross-fitting:} do again the other way round, average the two estimates, get CI via bootstrapping

\noindent \textbf{problems:} unclear choice of algorithm, is bias small enough?






\end{multicols}

%-------------------------------------------------------------------------------

% SECTION: LONGITUDINAL

%-------------------------------------------------------------------------------

\section{Longitudinal Data}
\begin{multicols}{2}

\paragraph{\large Time-Varying Treatments} compare 2 treatments

\noindent treatment history up to $k$: $\bar{A}_k=(A_0, A_1, ..., A_k)$

\noindent shorthand: always treated $\bar{A} = \bar{1}$, never treated $\bar{A} = \left(\bar{0}\right)$

\textbf{static strategy:} $g=\left[g_0(\bar{a}_{-1}), ..., g_K(\bar{a}_{K-1})\right]$

\textbf{dynamic strategy:} $g=\left[g_0(\bar{l}_0), ..., g_K(\bar{l}_K)\right]$

\textbf{stochastic strategy:} non-deterministic $g$

\noindent optimal strategy is where $\mathrm{E}\left[Y^g\right]$ is maximized (if high is good)






\paragraph{\large Sequential Identifiability} sequential versions of

 \textbf{exchangability:}
$Y^g \indep A_k| \bar{A}_{k-1} \,\,\, \forall g, k=0,1,...,K$

\textit{conditional exchangeability:}
$$\left(Y^g, L^g_{k+1}\right) \indep A_k| \bar{A}_{k-1} {=} g\left(\bar{L}_k\right), \bar{L}^k \,\,\, \forall g, k=0,1,...,K$$

 \textbf{positivity:} $f_{\bar{A}_{k-1},\bar{L}_k}(\bar{a}_{k-1},\bar{l}_k)\neq 0 \,\, \Rightarrow$
$$ f_{A_k|\bar{A}_{k-1},\bar{L}_k}(a_k|\bar{a}_{k-1},\bar{l}_k)>0 \,\, \forall \left(\bar{a}_{k-1},\bar{l}_k\right)$$

 \textbf{consistency:} 
\begin{align*}
Y^{\bar{a}} = Y^{\bar{a}^*} & \, \text{ if } {\bar{a}} = {\bar{a}^*};  & \,
Y^{\bar{a}} = Y & \, \text{ if } {\bar{A}} = {\bar{a}};  \\
\bar{L}^{\bar{a}}_k = \bar{L}^{\bar{a}^*}_k & \, \text{ if } {\bar{a}_{k-1}} = {\bar{a}^*_{k-1}}; & \,
\bar{L}^{\bar{a}}_k = \bar{L}_k & \, \text{ if } {\bar{A}_{k-1}} = {\bar{a}_{k-1}}
\end{align*}


\noindent \textbf{generalized backdoor criterion} (static strategy):\,all backdoors into $A_k$ (except through future treatments) are blocked $\forall k$ 


\noindent \textbf{static sequential exchangeability for $\boldsymbol{Y^{\bar{a}}}$}
$$Y^{\bar{a}} \indep A_k| \bar{A}_{k-1}, \bar{L}_k \,\,\,\,\, \text{ for } k=0,1,...,K$$
use SWIGs to visually check d-separation

\noindent \textbf{time-varying confounding} $\mathrm{E}\left[Y^{\bar{a}}|L_0\right] \neq \mathrm{E}\left[Y|A=\bar{a}, L_0\right]$


\paragraph{\large Treatment-Confounder Feedback} $A_0 \rightarrow L_1 \rightarrow A_1$: an unmeasured $U$ influencing $L_1$ and $Y$ turns $L_1$ into a collider;

\noindent traditional adjustment (e.\,g. stratification) biased: use g-methods

\noindent \textbf{g-null test} sequential exchangeability \& sharp null true $\Rightarrow$ $Y^g = Y \,\, \forall g$ $\,\,\,\,\Rightarrow \,\,\,\,$ $Y \indep A_0|L_0$ \& $Y \indep A_1|A_0, L_0, L_1$;
therefore: \newline if last two independences don't hold, one assumption is violated

\noindent \textbf{g-null theorem:} $\mathrm{E}\left[Y^g\right] = \mathrm{E}\left[Y\right]$, if the two independences hold \newline($\Rightarrow$ sharp null: only if strong faithfulness (no effect cancelling))



\paragraph{\large Standardization} over all possible $\bar{l}$-histories

\noindent simulates joint distribution of counterfactuals $\left(Y^{\bar{a}}, \bar{L}^{\bar{a}}\right)$ for $\bar{a}$
\begin{align*}
& \text{discrete: } \mathrm{E}\left[Y^{\bar{a}}\right] = \sum_{\bar{l}} \mathrm{E}\left[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l} \right] \prod_{k=0}^K f \left(l_k|\bar{a}_{k-1}, \bar{l}_{k-1}\right)  \\ &
\text{continuous: } \int f(y|\bar{a}, \bar{l}) \prod_{k=0}^K dF\left(l_k|\bar{a}_{k-1}, \bar{l}_{k-1}\right)
\end{align*}

\noindent for \textit{stochastic strategies} multiply with $\prod_{k=0}^K f^{int} \left(a_k|\bar{a}_{k-1}, \bar{l}_{k}\right) $
\noindent \textbf{g-null paradox} %todo p. 265


\paragraph{\large IP Weighting} 

$$ W^{\bar{A}} = \prod_{k=0}^K \frac{1}{f\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$$


$$ SW^{\bar{A}} = \prod_{k=0}^K \frac{f\left(A_k|\bar{A}_{k-1}\right)}{f\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$$

\paragraph{\large Doubly Robust Estimator} reduce misspecification bias

1. IP weights at each time $m$: $W^{\bar{A}_m} = \prod_{k=0}^m\frac{1}{f\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$

2. fit outcome regression with variable $R = \begin{cases} +W^A & \text{if } A{=}1 \\ -W^A & \text{if } A{=}0 \end{cases}$ \vspace{-0.9em}

3. calculate standardized mean outcome

\noindent valid, if treatment or outcome model correct, or treatment correct until k and outcome otherwise ($k+1$ robustness)











\paragraph{g-estimation} chapter 21.4

\paragraph{censoring} chapter 21.5


\paragraph{target trial} chapter 22 (does that even really fit in here, maybe push to 3rd paragraph in without models)



\end{multicols}


\def\bibpreamble{\textit{If no citation is given, the source is \citep{hernan2023causal}} \vspace{1.5em}}

\bibliographystyle{apalike} % We choose the "plain" reference style
\bibliography{cite} % Entries are in the refs.bib file



\end{document}