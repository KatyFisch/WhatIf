\documentclass[8pt]{extarticle}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage[a4paper,left=2.3cm,right=1.2cm,top=2cm,bottom=2cm]{geometry} 
\usepackage{blindtext}
\usepackage{setspace}
\usepackage{float}
\usepackage{titletoc}
\usepackage{titlesec}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{amsmath} 
\usepackage{multicol}
\usepackage{amsfonts} 
\usepackage{comment}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage{wrapfig}
\usepackage{verbatimbox}
\usepackage{enumitem}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{bigints}
\onehalfspacing
\usepackage[hidelinks]{hyperref}
\usepackage[all]{nowidow} %funktioniert nicht....
\clubpenalty=9996
\widowpenalty=9999
\brokenpenalty=4991
\predisplaypenalty=10000
\postdisplaypenalty=1549
\displaywidowpenalty=1602
\usepackage[round]{natbib} 
\usepackage{enumitem}
\usepackage{tcolorbox}

\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}

\allowdisplaybreaks

\setlength\parindent{0pt}

\newcommand{\zerodisplayskips}{%
  \setlength{\abovedisplayskip}{2pt}%
  \setlength{\belowdisplayskip}{2pt}%
  \setlength{\abovedisplayshortskip}{2pt}%
  \setlength{\belowdisplayshortskip}{2pt}}
\appto{\normalsize}{\zerodisplayskips}
\appto{\small}{\zerodisplayskips}
\appto{\footnotesize}{\zerodisplayskips}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\indep}{\perp \!\!\! \perp}

%Hier sind die unterschiedlichen Ausführlichkeitsgrade definiert
\includecomment{Extensiv} 
\includecomment{Proof} 
\includecomment{Annahmen}
\includecomment{Mathspez}
\includecomment{Mathfolg}
\includecomment{Rechreg}
\mdfdefinestyle{MyFrame}{%
    linecolor=black!20!,
    outerlinewidth=0.2pt,
    roundcorner=5pt,
    innertopmargin=0.5\baselineskip,
    innerbottommargin=0.5\baselineskip,
    innerrightmargin=10pt,
    innerleftmargin=10pt,
    backgroundcolor=white}
\specialcomment{Proof}{\begin{mdframed}[style=MyFrame,nobreak=false]  }{\end{mdframed}}
\specialcomment{Rechreg}{\noindent \textit{Calculation Rules:} \begin{itemize}[nosep,label=$\star$] }{\end{itemize}}
\renewcommand\ThisComment[1]{% Fix for Umlauts in comments
  \immediate\write\CommentStream{\unexpanded{#1}}%
}

% Hier die Ausführlichkeit bestimmen:
%\excludecomment{Extensiv} 
%\excludecomment{Proof} 
%\excludecomment{Annahmen}
%\excludecomment{Mathspez}
%\excludecomment{Mathfolg}

% Inhaltsverzeichnis mit zwei Spalten
\usepackage[toc]{multitoc}
\renewcommand*{\multicolumntoc}{2}




%Überschriftengrößen anpassen, so dass Paragraph kleiner ist als Subsubsection
\titleformat{\section}
  {\normalfont\fontsize{16}{15}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\fontsize{14}{15}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalfont\fontsize{12}{15}\bfseries}{\thesubsubsection}{1em}{}


\begin{document}

\topskip0pt
\vspace*{18em}

\hrule
\begin{center}
{\fontsize{30}{60}\selectfont \textbf{Causal Inference}} \\ \

{\fontsize{20}{60}\selectfont a summary}
\end{center}
\hrule

\tableofcontents




% weitere Anpassungen im Hauptteil des Dokuments
\raggedright %linksbündig
\setlength{\parindent}{15pt} %Einzuglänge festsetzen
\setlength{\columnseprule}{0.3pt} %Liniendicke zwischen zwei Multicols






%-------------------------------------------------------------------------------

% SECTION: GENERAL

%-------------------------------------------------------------------------------

\section{General}

\begin{multicols}{2}

\paragraph{\large Causal Roadmap} \citep{petersen2014causal} 
systematic approach linking causality to statistical procedures

\noindent \textbf{1. Specifying Knowledge.} structural causal model (unifying counterfactual language, structural equations, \& causal graphs): a set of possible data-generating processes, expresses background knowledge and its limits

\noindent \textbf{2. Linking Data.} specifying measured variables and sampling specifics (latter can be incorporated into the model)

\noindent \textbf{3. Specifying Target.} define hypothetical experiment: decide
\noindent\begin{enumerate}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item variables to intervene on: one (point treatment), multiple (longitudinal, censoring/missing, (in)direct effects)
\item intervention scheme: static, dynamic, stochastic
\item counterfactual summary of interest: absolute or relative, marginal structural models, interaction, effect modification
\item population of interest: whole, subset, different population
\end{enumerate}

\noindent \textbf{4. Assessing Identifiability.} are knowledge and data sufficient to derive estimand and if not, what else is needed?

\noindent \textbf{5. Select Estimand.} current best answer: knowledge-based assumptions $+$ which minimal convenience-based asspumptions (transparency) gets as close as possible

\noindent \textbf{6. Estimate.} choose estimator by statistical properties, nothing causal here

\noindent \textbf{7. Interpret.} hierarchy: statistical, counterfactual, feasible intervention, randomized trial


\paragraph{\large Average Causal Effect} $\mathrm{E}\left[Y^{a=1}\right] \neq \mathrm{E}\left[Y^{a=0}\right]$
\begin{align*}
\mathrm{E}\left[Y^{a}\right]   &=  \sum_yyp_{Y^a}(y)  &\text{(discrete)}\\
   &=  \int yf_{Y^a}(y)dy &\text{(continuous)}
\end{align*}

\noindent individual causal effect $Y_i^{a=1} \neq Y_i^{a=0}$ generally unidentifiable

\noindent \textit{null hypothesis:} no average causal effect

\noindent \textit{sharp null hypothesis:} no causal effect for any individual

\noindent \textbf{notation} $A,Y$: random variables (differ for individuals);
$a,y$: particular values; counterfactual $Y^{a=1}$: $Y$ under treatment $a=1$

\noindent  \textbf{stable unit treatment value assumption (SUTVA)} $Y_i^a$ is well-defined: no interference between individuals, no multiple versions of treatment (weaker: treatment variation irrelevance)

\noindent  \textbf{causal effect measures} typically based on means

\textit{risk difference:}  $\mathrm{Pr}\left[Y^{a=1}=1\right] - \mathrm{Pr}\left[Y^{a=0}=1\right]$

\textit{risk ratio:} $\frac{\mathrm{Pr}\left[Y^{a=1}=1\right]}{ \mathrm{Pr}\left[Y^{a=0}=1\right]}$

\textit{odds ratio:} $\frac{\mathrm{Pr}\left[Y^{a=1}=1\right]/\mathrm{Pr}\left[Y^{a=1}=0\right]}{ \mathrm{Pr}\left[Y^{a=0}=1\right]/\mathrm{Pr}\left[Y^{a=0}=0\right]}$

\noindent \textit{number needed to treat (NNT)} to save 1 life: $-1/$risk difference

\noindent \textbf{sources of random error}: sampling variability (use consistent estimators), nondeterministic counterfactuals

\noindent\textbf{association} compares $E\left[Y|A=1\right]$ and $E\left[Y|A=0\right]$, \textbf{causation} compares $E\left[Y^{a=1}\right]$ and $E\left[Y^{a=0}\right]$ (whole population)









\paragraph{\large Target Trial} emulating an ideal randomized experiment

\noindent explicitly formulate target trial \& show how it is emulated $\rightarrow$ \newline less vague causal question, helps spot issues

\noindent \textbf{missing data problem} unknown counterfactuals

\noindent \textit{randomized experiments:} missing completely at random $\rightarrow$ exchangeability (= exogeneity as treatment is exogenous)

\noindent \textit{ideal randomized experiment:} no censoring, double-blind, well-defined treatment, \& adherence $\rightarrow$ association is causation

\noindent \textit{pragmatic trial:} no placebo/blindness, realistic monitoring


\noindent \textbf{PICO} (population, intervention, comparator, outcome): some components of target trial

\noindent \textbf{three types of causal effects:}

\textit{intention-to-treat effect} (effect of treatment assignment)

\textit{per-protocol effect} (usually dynamic when toxicity arises)

\textit{other intervention effect} (strategy changed during follow-up)


\noindent \textbf{controlled direct effects:} effect of A on Y not through B

\textit{natural direct effect}  $A$ on $Y$ if $B^{a=0}$ (cross-world quantity)

\textit{principal stratum effect} $A$ on $Y$ for subset with $B^{a=0} = B^{a=1}$

\noindent \textbf{crossover experiment:} sequential treatment \& outcome $t{=}0,1$
\newline
individual causal effect $Y_{it}^{a_t=1} - Y_{it}^{a_t=0}$ only identifiable if: no carryover effect, effect $\indep$ time, outcome $\indep$ time

\noindent \textbf{time zero} if eligibility at multiple $t$ (observational data):
earliest, random $t$, all $t$ (adjust variance with bootstrapping)

\noindent \textbf{grace periods:} usually treatment starts $x$ months after first eligible, if death before: randomly assign strategy/copy into both




\paragraph{\large Identifiability Conditions} hold in ideal experiments

\noindent \textbf{consistency} counterfactuals correspond to data $Y=Y^A$: \newline
 if $A=a$, then $Y^a=Y$ for each individual
 
\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item precise definition of $Y^a$ via specifying $a$ (sufficiently well-defined $a$ maybe impossible (effect of DNA before it was discovered), relies on expert consensus)
\item linkage of counterfactuals to data ($a$ must be seen in data) 
\end{itemize}

\noindent \textbf{positivity} $\mathrm{Pr}\left[A=a|L=l\right] >0 \,\,\, \forall \, l \text{ with } \mathrm{Pr}\left[L=l\right]>0$; $$f_L(l)\neq 0 \Rightarrow f_{A|L}(a|l)>0 \,\, \forall a,l$$

\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item structural violations (inference not on full population)
\item random variability (smooth over with parametric models)
\end{itemize}
\noindent can sometimes be empirically verified (if all is seen in data)

\noindent \textbf{exchangeability} unverifiable without randomization
\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item \textit{marginal:} $Y^a \indep A$ $\widehat{=}$ randomized experiment, \newline counterfactuals are missing completely at random (MCAR)

\item \textit{conditional:} $Y^a {\indep} A|L$ $\widehat{=}$ conditionally randomized, counterfactuals are missing at random (MAR)
\end{itemize}
alternative definition: $ \mathrm{Pr}\left[A=1|Y^{a=0}, L\right] = \mathrm{Pr}\left[A=1|L\right]$

\noindent \textbf{additional conditions:}

\noindent \textit{correct measurement} mismeasurement of $A, Y, L$ results in bias

\noindent \textit{correct model specification} models $\overset{\text{may}}{\rightarrow}$ misspecification bias




\paragraph{\large Effect Modification} $A$ on $Y$ varies across levels of $V$

\noindent null average causal effect $\neq$ null causal effect per subgroup

\noindent \textbf{population characteristics:} causal effect measure is actually ``effect in a population with a particular mix of effect modifiers''

\noindent \textbf{transportability:} extrapolation of effect to another population (issues: effect modification, versions of treatment, interference)

\noindent effects conditional on $V$ may be more transportable

\noindent \textbf{types:} additive/multiplicative scale,
qualitative (effect in opposite directions)/quantitative, surrogate/causal 


\noindent \textbf{calculation:} 
\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item \textit{stratify} by $V$ then standardize/IP weight for $L$, 
\item $L$ as \textit{matching} factor (ensures positivity, difficult if high-dimensional $L$)
\end{itemize}

\noindent \textbf{collapsibility:}  causal risk difference and ratio are weighted averages of stratum-specific risks, can not be done for odds ratio



\paragraph{\large Interaction} effects of joint interventions $A$ and $E$
$$\mathrm{Pr}\left[Y^{1,1}=1\right] - \mathrm{Pr}\left[Y^{0,1}=1\right] \neq \mathrm{Pr}\left[Y^{1,0}=1\right] - \mathrm{Pr}\left[Y^{0,0}=1\right]$$
above definition for additive scale


sufficient component-cause framework

effects of simultaneous treatment: joint interventions $A$ and $E$

A and E have equal status

different than effect modification: $V$ is not an intervention variable

exchangeability for both $A$ and $E$ needed


interaction is superadditive/-multiplicative if positive (sub- if negative)

when treatment $E$ is randomly assigned: same as effec modification

monotonic effect: same direction for each individual (or no effect)


\paragraph{\large sufficient component-cause framework}

response type (helped, immune, hurt, doomed) turns to 16 types for binary $A$ and $E$

(minimal) sufficient cause: 

(minimal) $U_1$ together with $A=1$ ensure $Y=1$

(minimal) $U_2$ together with $A=0$ ensure $Y=1$




\paragraph{causal diagrams} chapter 6, include swigs from 7.5 and that one technical point

more on SWIGS p 242ff

\paragraph{confounding} chapter 7

\paragraph{selection bias} chapter 8

\paragraph{measurement bias} chapter 9

\paragraph{random variabilty} chapter 10



\end{multicols}



%-------------------------------------------------------------------------------

% SECTION: MODELS

%-------------------------------------------------------------------------------

\section{Models}

\begin{multicols}{2}

\paragraph{\large Modeling} data are a sample from the target population \vspace{0.4em}

\noindent \hspace{0.9em}\begin{tabular}{l l l}
\textbf{\it estimand:} & quantity  of interest, & e.\,g.\ $\mathrm{E}\left[Y|A=a\right]$ \\
\textbf{\it estimator:} & function to use, & e.\,g.\ $\widehat{\mathrm{E}}\left[Y|A=a\right]$ \\
\textbf{\it estimate:} & apply function to data, & e.\,g.\ $4.1$ 
\end{tabular} \vspace{0.5em}

\noindent \textbf{model}: a priori restriction of joint distribution/dose-response curve;  \textit{assumption:} no model misspecification (usually wrong)

\noindent \textbf{non-parametric estimator:} no restriction (saturated model) $=$ \textit{Fisher consistent estimator} (entire population data $\rightarrow$ true value)

\noindent \textbf{parsimonious model:} few parameters estimate many quantities

\noindent \textbf{bias-variance trade-off:} \newline wiggliness $\uparrow$ $\rightarrow$ misspecification bias $\downarrow$, CI width $\uparrow$

\paragraph{\large Variable Selection} can induce bias if $L$ includes: 

\hspace{-0.2em}\vspace{-1em}
\begin{tabular}{l l }
 (decendant of) collider:& \textit{selection bias under the null}\\
 noncollider effect of $A$:& \textit{selection bias under the alternative}\\
 mediator:& \textit{overadjustment for mediators}
\end{tabular}

\noindent temporal ordering is not enough to conclude anything

\noindent \textbf{bias amplification:} e.g. by adjusting for an instrument $Z$ (can also reduce bias)





\paragraph{\large Machine Learning} $L$ is high-dimensional

\noindent use lasso or ML for IP weighting/standardization

\noindent \textbf{\textit{but:}} ML does not guarantee elimination of confounding and has largely unknown statistical properties

\noindent $\rightarrow$ \textbf{doubly robust estimator:} consistent if bias  $< \frac{1}{\sqrt{n}}$

\noindent \textit{sample splitting:} train estimators on training sample, use resulting estimators for doubly robust method on estimation sample (CIs on estimation sample are valid, but $n$ halved)

\noindent \textit{cross-fitting:} do again the other way round, average the two estimates, get CI via bootstrapping

\noindent \textbf{problems:} unclear choice of algorithm, is bias small enough?



\paragraph{\large Super Learning} \citep{van2007super, van2011targeted}

\noindent \textbf{oracle selector:} select best estimator of set of learners $Z_i$

\noindent \textbf{discrete super learner:} select algorithm with smallest cross-validated error (converges to oracle for large sample size)

\noindent \textbf{super learner:} improves asymptotically on discrete version

$\mathrm{logit} (Y=1|Z) = \sum_i \alpha_i Z_i, $ with $0<\alpha_i<1$ and $\sum\alpha_i=1$
weights $\alpha_i$ are determined inside the cross-validation; for the prediction, $Z_i$ trained on the full data set are used

\noindent   can be cross-validated itself to check for overfitting (unlikely)












\end{multicols}

\subsection{Traditional Methods}

\begin{multicols}{2}




\paragraph{\large Stratification}  calculate risk for each stratum of $L$

\noindent only feasible if enough data per stratum
















\paragraph{Outcome regression} chapter 15

\paragraph{instrumental variable estimation} chapter 16

\paragraph{causal survival analysis} chapter 17 (and technical point 22.3)







\end{multicols}


%-------------------------------------------------------------------------------

% SECTION: G-METHODS

%-------------------------------------------------------------------------------

\subsection{G-Methods}
\begin{multicols}{2}


\paragraph{\large G-Methods} \textit{g}eneralized treatment contrasts:
adjust for (surrogate) confounders $L$




\begin{itemize}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item \textbf{standardization} two types of g-formula
\item \textbf{IP weighting} also g-formula
\item \textbf{g-estimation:} not needed unless longitudinal
\end{itemize}

\paragraph{\large Standardization} plug-in (or parametric if so) g-formula
$$\mathrm{E}\left[Y^{a}\right] = \overbrace{\mathrm{E}\left[\mathrm{E}\left[Y|A{=}a,L{=}l\right]\right]}^{\text{conditional expectation}} =  \overbrace{ \textstyle{\int} \mathrm{E}\left[Y|L=l, A=a\right]f_L\left[l\right]dl}^{\text{joint density estimator}} $$
weighted average of stratum-specific risks; unknowns can be estimated non-parametrically or modeled

\noindent \textbf{no need to estimate $\boldsymbol{f_L\left[l\right]}$/integrate} as empirical distribution can be used: estimate outcome model $\rightarrow$ predict counterfactuals on whole dataset $\rightarrow$ average the results ($\rightarrow$ CI by bootstrapping)

\noindent \textbf{for discrete $\boldsymbol{ L}$}  $\mathrm{E}\left[Y|A=a\right] = \sum_l \mathrm{E}\left[Y|L=l, A=a\right]\mathrm{Pr}\left[L=l\right]$

\vspace{0.2em}
\noindent \colorbox{lightgray!20!white}{\begin{minipage}{28em}




\textbf{\textcolor{darkgray}{time-varying}} standardize over all possible $\bar{l}$-histories



\noindent simulates joint distribution of counterfactuals $\left(Y^{\bar{a}}, \bar{L}^{\bar{a}}\right)$ for $\bar{a}$
\textbf{joint density estimator (jde)}
\begin{align*}
& \text{discrete: } \mathrm{E}\left[Y^{\bar{a}}\right] = \sum_{\bar{l}} \mathrm{E}\left[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l} \right] \prod_{k=0}^K f \left(l_k|\bar{a}_{k-1}, \bar{l}_{k-1}\right)  \\ &
\text{continuous: } \int f(y|\bar{a}, \bar{l}) \prod_{k=0}^K f\left(l_k|\bar{a}_{k-1}, \bar{l}_{k-1}\right)dl
\end{align*}

\noindent for \textit{stochastic strategies} multiply with $\prod_{k=0}^K f^{int} \left(a_k|\bar{a}_{k-1}, \bar{l}_{k}\right) $


\begin{mdframed}[linecolor=black!20!,
    outerlinewidth=0.2pt,
    innertopmargin=0.5\baselineskip,
    innerbottommargin=0.5\baselineskip,
    backgroundcolor=lightgray!20!white, innerleftmargin=2pt, innerrightmargin=2pt]
\textbf{estimation} \citep{young2011comparative, schomaker_using_2019}

\begin{enumerate}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item model $f \left(l_k|\bar{a}_{k-1}, \bar{l}_{k-1}\right)$ and $\mathrm{E}\left[Y|\bar{A}=\bar{a}, \bar{L}=\bar{l} \right]$
\item simulate data forward in time: \newline
at $k=0$: use empirical distribution of $L_0$ (observed data) \newline
at $k>0$: set $\bar{A} = \bar{a}$, \textit{draw} from models estimated in 1.
\item calculate mean of $\hat{Y}_{K,i}^{\bar{a}}$ (bootstrap for CI)
\end{enumerate}



\end{mdframed}


\textbf{iterated conditional expectation (ice)} 
$$\mathrm{E}\left[ Y_T^{\bar{a}}\right] = \mathrm{E} \left[ \mathrm{E} \left[\mathrm{E} \left[ ... \mathrm{E} \left[Y_T| \bar{A}_{T{-}1} {=} \bar{a}_{T{-}1}, \bar{L}_T \right]  ...|\bar{A}_0 {=} a_0, L_1 \right] |L_0 \right]\right]$$

\end{minipage}}

\noindent \colorbox{lightgray!20!white}{
\begin{minipage}{28em}


\begin{mdframed}[linecolor=black!20!,
    outerlinewidth=0.2pt,
    innertopmargin=0.5\baselineskip,
    innerbottommargin=0.5\baselineskip,
    backgroundcolor=lightgray!20!white, innerleftmargin=2pt, innerrightmargin=2pt]
\textbf{estimation} \citep{schomaker_using_2019}

\begin{enumerate}[itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt, leftmargin=1.5em]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item model inside out: $Q_{T} {=} \mathrm{E} \left[Y_T| \bar{A}_{T{-}1}, \bar{L}_T \right]$ to $Q_0 {=} \mathrm{E} \left[Q_1| \bar{L}_0 \right]$, predict $Q_t$ with $\bar{A} = \bar{a}$ in each step
\item calculate mean of $\hat{Q}_{0,i}^{\bar{a}}$ (bootstrap for CI)
\end{enumerate}



\end{mdframed}

\noindent \textbf{g-null paradox} even if the sharp null holds, model misspecification can lead to it being falsely rejected

\end{minipage}}



\begin{mdframed}[style=MyFrame,nobreak=true, innerleftmargin=2pt, innerrightmargin=2pt]
Proof: for $L_0 \rightarrow A_0 \rightarrow Y_0 \rightarrow L_1 \rightarrow A_1 \rightarrow Y_1$, $\bar{a} =(a_0,a_1)$ 
\begin{alignat*}{4} 
\mathrm{E}\left[Y_1^{\bar{a}}\right] & \overset{\text{CE}}{=} && \mathrm{E}\left[\mathrm{E}\left[   Y_1^{\bar{a}}|A_0{=}a_0, L_0   \right]\right]  \\ 
\text{(ice)}\,\,\, &\overset{\text{CE*}}{=} && \mathrm{E}\left[\mathrm{E}\left[  \mathrm{E}\left[Y_1|\bar{L}, \bar{A}{=}\bar{a}, Y_0 \right]| A_0{=}a_0, L_0   \right]\right]  \\ 
&\overset{\text{LTP}}{=} && \mathrm{E}\left[ \sum\nolimits_{l_1} \mathrm{E}\left[Y_1|A_0{=}a_0, \bar{L}, Y_0\right] \mathrm{Pr}\left[l_1|a_0,l_0, y_0\right]         \right] \\
&\overset{\text{LTP}}{=} && \sum\nolimits_{l_0}\!\!\!\left[ \sum\nolimits_{l_1} \!\!\!\mathrm{E}\left[Y_1|A_0{=}a_0, \bar{L}, Y_0\right] \mathrm{Pr}\left[l_1|a_0,l_0, y_0\right]         \right] \mathrm{Pr}\left[l_0\right] \\
\text{(jde)}\,\,\, &\overset{\text{sum}}{=} &&  \sum\nolimits_{\bar{l}} \mathrm{E}\left[Y_1|A_0{=}a_0, \bar{L}, Y_0\right] \mathrm{Pr}\left[l_1|a_0,l_0\right]          \mathrm{Pr}\left[l_0\right] 
\end{alignat*}
CE: conditional expectation; *: exchangeability; \newline LTP: law of total probability
\end{mdframed}


















\paragraph{\large Marginal Structural Models} association is causation in the IP weighted pseudo-population 
$$\text{associational model } \mathrm{E}\left[Y|A\right] = \text{ causal model } \mathrm{E}\left[Y^a\right]$$

\noindent \textit{step 1:} estimate/model $f\left[A|L\right]$ (and $f\left[A\right]$) $\rightarrow$ get $(S)W^A$

\noindent \textit{step 2:} estimate regression parameters for pseudo-population

\noindent \textbf{effect modification} variables $V$ can be included (e.\,g.\ $\beta_0+\beta_1 a+\beta_2 V a + \beta_3 V$; technically not marginal anymore), $SW^A(V) = \frac{f\left[A|V\right]}{f\left[A|L\right]}$ more efficient than $SW^A$
 

\paragraph{\large Censoring} measuring joint effect of $A$ and $C$
$$\mathrm{E}\left[Y^{a, c=0}\right] \text{ is of interest}$$

\noindent \textbf{standardization} $\mathrm{E}\left[Y|A=a\right] = \int \mathrm{E}\left[Y|L{=}l, A{=}a, C{=}0\right]dF_L\left[l\right]$\vspace{0.2em}

\noindent \textbf{IP weights}\vspace{-1.30em}

\hspace{3.5em}\begin{tabular}{l l l}
$W^{A,C}=W^A \times W^C$  &(uses $n$) & or \\
$SW^{A,C}=SW^A \times SW^C$ &(uses $n^{c=0}$) & 
\end{tabular}\vspace{0.3em}

\noindent \textbf{g-estimation} can only adjust for confounding, not selection bias $\rightarrow$ use IP weights






\paragraph{\large G-Estimation} (additive) structural nested models %todo: verbesserung von allem, ich habs noch nicht ganz verstanden
\begin{align*}
\mathrm{logit} \, \mathrm{Pr}\left[A=1|H(\psi^\dagger), L\right] &= \alpha_0 + \alpha_1H(\psi^\dagger) + \alpha_2L \\
H(\psi^\dagger) &= Y - \psi_\dagger A
\end{align*}
find $\psi^\dagger$ which renders $\alpha_1=0$; 95\,\%-CI: all $\psi^\dagger$ for which $p>0.05$
closed-form solution for linear models


\noindent \textbf{derivation:} $H(\psi^\dagger) = Y^{a=0}$
$$\mathrm{logit} \, \mathrm{Pr}\left[A=1|Y^{a=0}, L\right] = \alpha_0 + \alpha_1Y^{a=0} + \alpha_2L$$
$Y^{a=0}$ unknown, but because of exchangeability $\alpha_1$ should be zero
$$Y^{a=0} =Y^a - \psi_1 a$$
equivalent to $Y^{a=0} =Y^{a=1} - \psi_1$, but using no counterfactuals



\noindent \textbf{structural nested mean model}
\begin{align*}
\text{additive: }\,\,\, & \mathrm{E}\left[Y^a-Y^{a=0}|A=a, L\right] &= \beta_1 a \,(+ \beta_2 a L) \\
\text{multiplicative: }\,\,\, & \log \left( \frac{\mathrm{E}\left[Y^a|A=a, L\right]}{\mathrm{E}\left[Y^{a=0}|A=a, L\right]} \right) &= \beta_1 a \,(+ \beta_2 a L)
\end{align*} 
multiplicative is preferred if $Y$ always positive, but does not extend to longitudinal case

\noindent semi-parametric: agnostic about $\beta_0$ and effect of $L$ $\rightarrow$ robust $\uparrow$

\noindent \textbf{no time-varying:} no nesting; model equals marginal structural models with missing $\beta_0, \beta_3$ (unspecified ``no treatment'')

\noindent \textbf{sensitivity analysis:} unmeasured confounding ($\alpha_1 \neq 0$) can be examined: do procedure  for different values of $\alpha_1$ $\rightarrow$ plot $\alpha_1$ vs.\ $\psi^\dagger$ $\rightarrow$ how sensitive is  estimate to unmeasured confounding?

\noindent \textbf{effect modification:} add $V$ in both g-estimation equations %todo


\noindent \textbf{doubly robust estimators} exist%todo


\paragraph{\large IP Weighting} \textit{i}nverse \textit{p}robability of treatment (g-formula)
$$\mathrm{E}\left[Y^{a}\right] = \mathrm{E}\left[\frac{I(A=a)Y}{f\left[A|L\right]}\right]; W^A=\frac{1}{f\left[A|L\right]}; SW^A = \frac{f(A)}{f\left[A|L\right]}$$

\noindent unknowns can be estimated non-parametrically or modeled
\noindent \textbf{pseudo-population:} everyone is treated \& untreated ($L\not\to A$)

\noindent \textbf{FRCISTG} \textit{(fully randomized causally interpreted structured graph)}: probability tree for $L \rightarrow A \rightarrow Y$, can be used to calculate/visualize simulation of values for $A$ 

\noindent \textbf{for discrete $\boldsymbol{A, L}$} $f\left[a|l\right] = \mathrm{Pr}\left[A=a,L=l\right]$

\noindent \textbf{estimators:} Horvitz-Thompson; Hajek (modified version) %todo p.152 

\noindent \textbf{stabilized weights $\boldsymbol{SW^A}$} should have an average of 1 (check!) $\rightarrow$ pseudo-population same size $\rightarrow$ CI width $\downarrow$

\paragraph{\large Standardization and IP Weighting}

are equivalent, \textit{\textbf{but}} if modeled, different ``no misspecification'' assumptions:

standardization: outcome model

IP weighting: treatment model

\noindent \textbf{doubly robust estimators:} reduce model misspecification bias, consistent if either model is correct; \textbf{\textit{e.\,g.:}} \vspace{-0.9em}

1. fit outcome regression with variable $R = \begin{cases} +W^A & \text{if } A{=}1 \\ -W^A & \text{if } A{=}0 \end{cases}$ \vspace{-0.9em}

2. standardize by averaging



\subsubsection{Time-varying A}







\paragraph{\large IP Weighting} 

$$ W^{\bar{A}} = \prod_{k=0}^K \frac{1}{f\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$$


$$ SW^{\bar{A}} = \prod_{k=0}^K \frac{f\left(A_k|\bar{A}_{k-1}\right)}{f\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$$

\paragraph{\large Doubly Robust Estimator} sequential estimation
\begin{enumerate}[leftmargin=*, itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item 
estimate $\hat{f}\left(A_m|\bar{A}_{m-1}, \bar{L}_m\right)$ (e.\,g.\ logistic model), use it to \newline
calculate at each time $m$: $\widehat{W}^{\bar{A}_m} = \prod_{k=0}^m\frac{1}{\hat{f}\left(A_k|\bar{A}_{k-1}, \bar{L}_k\right)}$ and modified IP weights at $m$: $\widehat{W}^{\bar{A}_{m-1, a_m}} = \frac{\widehat{W}^{\bar{A}_{m-1}}}{\hat{f}\left(a_m|\bar{A}_{m-1}, \bar{L}_m\right)} $
\item with $\widehat{T}_{K+1}:=Y$, recursively for $m=K, K-1, ..., 0$:\newline
 (a) fit outcome regression on $\widehat{T}_{m+1}$ with variable  $\widehat{W}^{\bar{A}_m}$\newline
 (b) calculate $\widehat{T}_{m}$ using the outcome model with $\widehat{W}^{\bar{A}_{m-1, a_m}}$
\item calculate standardized mean outcome $\widehat{\mathrm{E}}\left[Y^{\bar{a}}\right] = \mathrm{E}\left[\widehat{T}_0\right]$
\end{enumerate}

\noindent \textbf{valid, if} treatment or outcome model correct, or treatment correct until k and outcome otherwise ($k+1$ robustness)


\paragraph{\large G-Estimation} nested equations: for each time $k$

\noindent \textbf{strutural nested mean models} separate effect of each $a_k$
$$\mathrm{E}\left[Y^{\bar{a}_{k-1}, a_k, \underline{0}_{k+1}} - Y^{\bar{a}_{k-1}, \underline{0}_{k+1}}|\bar{L}^{\bar{a}_{k-1}}=\bar{l}_k, \bar{A}_{k-1} = \bar{a}_{k-1}\right] = $$
$$  a_k\gamma_k\left(\bar{a}_{k-1}, \bar{l}_k,\beta\right)$$
\noindent 

\noindent \textbf{calculations}
$$H_k\left(\psi^\dagger\right) = Y - \sum_{j=k}^K A_j \gamma_j\left(\bar{A}_{j-1}, \bar{L}_j, \psi^\dagger\right)$$
\noindent function $\gamma_j$ can be, e.\,g.\ constant ($\psi_1$), time-varying only ($\psi_1+\psi_2k$), or dependent on treatment/covariate history

$$\mathrm{logit}\,\mathrm{Pr}\left[A_k=1|H_k\left(\psi^\dagger\right), \bar{L}_k,\bar{A}_{k-1}\right]=$$
$$\alpha_0 +\alpha_1H_k\left(\psi^\dagger\right)+\alpha_2 w_k\left(\bar{L}_k,\bar{A}_{k-1}\right)
$$
find $\alpha_1$ that is closest to zero

a closed form estimator exists for the linear case



\paragraph{\large Censoring} $\bar{C}$: monotonic type of missing data 

\noindent \textbf{standardization}: $\int f(y|\bar{a}, \bar{c}{=}\bar{0}, \bar{l}) \prod_{k=0}^K dF\left(l_k|\bar{a}_{k-1}, c_{k-1} {=} 0, \bar{l}_{k-1}\right)$

\noindent \textbf{IP weighting}:
\noindent $$\textcolor{gray}{S}W^{\bar{C}}= \prod_{k=1}^{K+1}\frac{1\textcolor{gray}{\cdot \mathrm{Pr}\left(C_k=0|\bar{A}_{k-1}, C_{k-1}=0\right)}}{\mathrm{Pr}\left(C_k=0|\bar{A}_{k-1}, C_{k-1}=0, \bar{L}_k\right)} $$










\end{multicols}



\subsection{Advanced Methods}

\begin{multicols}{2}


\paragraph{\large TMLE} \textit{t}argeted \textit{m}inimum \textit{l}oss-based \textit{e}stimation
$$O=(W, A, Y) \sim P_0$$

\noindent target $\Psi((P_0) = \psi_0$, \textit{typically: $\mathrm{E}_{W,0}\left[\mathrm{E}_0(Y|A{=}1,W) - \mathrm{E}_0(Y|A{=}0,W)\right]$}

\noindent \textbf{first step:} outcome model $\bar{Q}^0_n(A,W)$ estimating $\bar{Q}_0$ (part of $P_0$)
\begin{itemize}[leftmargin=*, itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item  super learning is often used here, but leads to a biased estimate
\item not all of $f(Y|A,W)$ needs to be estimated, just the relevant portion, \textit{typically average  outcome $\mathrm{E}_0(Y|A,W)$}  $\rightarrow$ efficiency $\uparrow$
\end{itemize}
get predicted values for A=1 and A=0

\noindent \textbf{second step:} update $\bar{Q}^0_n(A,W)$ to $\bar{Q}^1_n(A,W)$ using treatment model $g_n$ estimating $g_0 = P_0(A|W)$ 
\begin{itemize}[leftmargin=*, itemsep=0em, topsep=0pt, partopsep=0pt,parsep=0pt]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
\item goal: bias reduction, get optimal bias-variance trade-off
\item super learning is used here as well
\item removes all asymptotic bias, if consistent estimator is used here
\item 
\end{itemize}
get predicted values $g_n(1|W_i)$ and $g_n(0|W_i)$

calculate clever covariate $H^*_n(A,W) = \left(\frac{I(A=1)}{g_n(1|W)} - \frac{I(A=0)}{g_n(0|W)}\right)$ for each $i$: $H^*_n(A,W) = \left(\frac{I(A=1)}{g_n(1|W)} - \frac{I(A=0)}{g_n(0|W)}\right)$

updating: logistic regression $\mathrm{logit} \bar{Q}_n^1(A,W) = \overbrace{\mathrm{logit} \bar{Q}_n^0(A,W)}^{\text{offset}}+ \epsilon_n H_n^*(A,W)$ (converges after first update)

$Q^*_n = (\bar{Q}^1_n, Q^0_{W,n})$

\noindent \textbf{third step:} TMLE is a substitution estimator $\psi_n^{TMLE} = \frac{1}{n}\sum_{i=1}^n \left[\bar{Q}^1_n(1,W_i) -  \bar{Q}^1_n(0,W_i)\right] $



\noindent \textbf{advantages:} doubly robust (consistent if either outcome or treatment model is correctly specified), asymptotically efficient (if both are correct), substition estimator (more robust to outliers and sparsity)




\ \\
\noindent --------------------------------------

$\mathcal{L}(O) = \overbrace{\mathrm{Pr}(Y|A, W)}^{Q_Y}\overbrace{\mathrm{Pr}(A|W)}^{g}\overbrace{\mathrm{Pr}(W)}^{Q_W}$



Second step: update model, incorporate infor on treatment assignment mechanisms to improve $\psi_0$
ML estimation regress residuals $Y = \bar{Q}^0_n + \epsilon H(A,W)$
$H(A,W)$ depends on target parameter and loss function but is a function of the propensitiy score
update initial fit $\bar{Q}^*_n = \bar{Q}^0_n + \hat{\epsilon}H(A,W)$


valid inference, good finite sample performance, 


$H(A,W)$ comes from the influence curve, targeting ensures mean of efficient influence curve $D^*(P)$  is zero

TMLE solves $P_nD^*(P^*_n)=0$


$$D^*(P) = \overbrace{\left[\frac{A}{g(1,W)} - \frac{1-A}{g(0,W)}\right] \left[Y-\bar{Q}(A,W)\right]}^{a} + \overbrace{\bar{Q}(1,W) - \bar{Q}(0,W) -\psi}^{b}   $$

g is propensity score


TMLE is a substitution estimator $\psi_n^{TMLE} = \frac{1}{2}\sum_{i=1}^n \bar{Q}^*_n(1,W_i) - \frac{1}{2}\sum_{i=1}^n \bar{Q}^*_n(0,W_i)$ therefore mean of b is zero

targeting step makes sure a also has mean zero

$Y=\epsilon H(A,W) + offset(\bar{Q}^0_n)$



MLE solves $\sum_{i=1}^n H(A_i, W_i)\left[Y_i-\bar{Q}^*_n(A_i,W_i)\right]=0$ where $\bar{Q}^*_n(A_i,W_i) = \hat{\epsilon}H(A,W) + \bar{Q}^0_n$
 therefore obvious choice: $H(A,W) = \frac{A}{g(1,W)} - \frac{1-A}{g(0,W)}$
 
 
 influence curve based inference: 
 asymptotic linearity $\sqrt{n}\left(\psi_n^{TMLE} - \psi_0\right) \overset{D}{\rightarrow} \mathrm{N}(0,\sigma^2)$
 
 95\% CI: $\psi_n \pm 1.96 \hat{\sigma}/\sqrt{n}$ with $\hat{\sigma}^2=\frac{1}{2}\sum_{i=1}^n \hat{D}^{*^2}(P^*_n)(O_i)$
 
 test statistic for null hypothesis $H_0$: $\psi_0=0$ $$T=\frac{\psi_n}{\sqrt{\hat{\sigma}^2/n}}$$
 
 p-values calculated as $2\Phi(-abs(T))$

\end{multicols}

%-------------------------------------------------------------------------------

% SECTION: LONGITUDINAL

%-------------------------------------------------------------------------------

\section{Longitudinal Data}
\begin{multicols}{2}

\paragraph{\large Time-Varying Treatments} compare 2 treatments

\noindent treatment history up to $k$: $\bar{A}_k=(A_0, A_1, ..., A_k)$

\noindent shorthand: always treated $\bar{A} = \bar{1}$, never treated $\bar{A} = \left(\bar{0}\right)$

\textbf{static strategy:} $g=\left[g_0(\bar{a}_{-1}), ..., g_K(\bar{a}_{K-1})\right]$

\textbf{dynamic strategy:} $g=\left[g_0(\bar{l}_0), ..., g_K(\bar{l}_K)\right]$

\textbf{stochastic strategy:} non-deterministic $g$

\noindent optimal strategy is where $\mathrm{E}\left[Y^g\right]$ is maximized (if high is good)






\paragraph{\large Sequential Identifiability} sequential versions of

 \textbf{exchangability:}
$Y^g \indep A_k| \bar{A}_{k-1} \,\,\, \forall g, k=0,1,...,K$

\textit{conditional exchangeability:}
$$\left(Y^g, L^g_{k+1}\right) \indep A_k| \bar{A}_{k-1} {=} g\left(\bar{L}_k\right), \bar{L}^k \,\,\, \forall g, k=0,1,...,K$$

 \textbf{positivity:} $f_{\bar{A}_{k-1},\bar{L}_k}(\bar{a}_{k-1},\bar{l}_k)\neq 0 \,\, \Rightarrow$
$$ f_{A_k|\bar{A}_{k-1},\bar{L}_k}(a_k|\bar{a}_{k-1},\bar{l}_k)>0 \,\, \forall \left(\bar{a}_{k-1},\bar{l}_k\right)$$

 \textbf{consistency:} 
\begin{align*}
Y^{\bar{a}} = Y^{\bar{a}^*} & \, \text{ if } {\bar{a}} = {\bar{a}^*};  & \,
Y^{\bar{a}} = Y & \, \text{ if } {\bar{A}} = {\bar{a}};  \\
\bar{L}^{\bar{a}}_k = \bar{L}^{\bar{a}^*}_k & \, \text{ if } {\bar{a}_{k-1}} = {\bar{a}^*_{k-1}}; & \,
\bar{L}^{\bar{a}}_k = \bar{L}_k & \, \text{ if } {\bar{A}_{k-1}} = {\bar{a}_{k-1}}
\end{align*}


\noindent \textbf{generalized backdoor criterion} (static strategy):\,all backdoors into $A_k$ (except through future treatments) are blocked $\forall k$ 


\noindent \textbf{static sequential exchangeability for $\boldsymbol{Y^{\bar{a}}}$}
$$Y^{\bar{a}} \indep A_k| \bar{A}_{k-1}, \bar{L}_k \,\,\,\,\, \text{ for } k=0,1,...,K$$
use SWIGs to visually check d-separation

\noindent \textbf{time-varying confounding} $\mathrm{E}\left[Y^{\bar{a}}|L_0\right] \neq \mathrm{E}\left[Y|A=\bar{a}, L_0\right]$


\paragraph{\large Treatment-Confounder Feedback} $A_0 \rightarrow L_1 \rightarrow A_1$: an unmeasured $U$ influencing $L_1$ and $Y$ turns $L_1$ into a collider;

\noindent traditional adjustment (e.\,g.\ stratification) biased: use g-methods

\noindent \textbf{g-null test} sequential exchangeability \& sharp null true $\Rightarrow$ $Y^g = Y \,\, \forall g$ $\,\,\,\,\Rightarrow \,\,\,\,$ $Y \indep A_0|L_0$ \& $Y \indep A_1|A_0, L_0, L_1$;
therefore: \newline if last two independences don't hold, one assumption is violated

\noindent \textbf{g-null theorem:} $\mathrm{E}\left[Y^g\right] = \mathrm{E}\left[Y\right]$, if the two independences hold \newline($\Rightarrow$ sharp null: only if strong faithfulness (no effect cancelling))



\end{multicols}


\def\bibpreamble{\textit{If no citation is given, the information is taken from the book \citep{hernan2020causal}} \vspace{1.5em}}

\bibliographystyle{apalike} % We choose the "plain" reference style
\bibliography{cite} % Entries are in the refs.bib file



\end{document}